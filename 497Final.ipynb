{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNmiYvDakBJt"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmaH8iTIkBJt"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0Q6lXuikBJu"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "325917e7-7e04-4d2f-cb19-775f20e31e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "794dc63b-912b-45c9-a2c5-de6d5f2d96ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.3.19 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "### Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjY75GoYUCB8",
        "outputId": "b0f4b158-5df1-4854-bfcf-b49940b92cbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "train_dataset length: 3200\n",
            "validation_dataset length: 400\n",
            "test_dataset length: 400\n",
            "hf_set length: 10\n",
            "\n",
            "Sample train text:\n",
            " Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "Antibiotic-based regimens are frequently used for the treatment of Helicobacter pylori infection .These regimens fail to eradicate H pylori in 15 % to 40 % of patients , primarily due to antimicrobial resistance and insufficient patient compliance .Effective prevention and eradication of H pylori by passive immunization with orally administered bovine antibodies has been demonstrated in animal studies , and may serve as an alternative therapy in humans .To study the efficacy and safety of orally administered bovine anti-H pylori antibodies for the reduction of intragastric bacterial load and eradication of H pylori in humans .\n",
            "\n",
            "### Response:\n",
            "Dairy cows were immunized against H pylori .After confirmation of the presence of anti-H pylori antibodies in the milk , the milk was subsequently processed into a whey protein concentrate ( WPC ) .In a prospective , double-blind , placebo-controlled randomized clinical trial , H pylori-infected subjects were randomly assigned to treatment with the WPC preparation or placebo .Study medication was continued for 28 days ; subjects were followed-up for 56 days .<|end_of_text|>\n"
          ]
        }
      ],
      "source": [
        "# ---------- FINAL DATA-PREP CELL (run AFTER you have `tokenizer`) ----------\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# file paths\n",
        "DATA_DIR = \"/content/drive/MyDrive/data\"\n",
        "paths = {\n",
        "    \"train\":      f\"{DATA_DIR}/train.csv\",\n",
        "    \"validation\": f\"{DATA_DIR}/validation.csv\",\n",
        "    \"test\":       f\"{DATA_DIR}/test.csv\",\n",
        "    \"hf_set\":     f\"{DATA_DIR}/humanFeedback.csv\",\n",
        "}\n",
        "\n",
        "# Alpaca‚Äêstyle template\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "EOS = tokenizer.eos_token or \"</s>\"\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    texts = [\n",
        "        alpaca_prompt.format(inp, ins, out) + EOS\n",
        "        for ins, inp, out in zip(\n",
        "            examples[\"instruction\"],\n",
        "            examples[\"input\"],\n",
        "            examples[\"output\"],\n",
        "        )\n",
        "    ]\n",
        "    return {\"text\": texts}\n",
        "\n",
        "# 1) Load train/validation/test with CSV loader\n",
        "raw = load_dataset(\n",
        "    \"csv\",\n",
        "    data_files={\n",
        "        \"train\":      paths[\"train\"],\n",
        "        \"validation\": paths[\"validation\"],\n",
        "        \"test\":       paths[\"test\"],\n",
        "    },\n",
        "    column_names=[\"instruction\", \"output\"],\n",
        ")\n",
        "\n",
        "# 2) Process each split, add the fixed input, format, then slice\n",
        "for split, size in [(\"train\", 3200), (\"validation\", 400), (\"test\", 400)]:\n",
        "    ds = raw[split]\n",
        "    # ‚Üê fill input with the same prompt for all examples\n",
        "    ds = ds.add_column(\n",
        "        \"input\",\n",
        "        [\"Construct a research methodology for the given problem.\"] * len(ds)\n",
        "    )\n",
        "    ds = ds.map(\n",
        "        formatting_prompts_func,\n",
        "        batched=True,\n",
        "        remove_columns=ds.column_names,\n",
        "    )\n",
        "    globals()[f\"{split}_dataset\"] = ds.select(range(size))\n",
        "\n",
        "# 3) human-feedback set: likewise fill input\n",
        "raw_hf = load_dataset(\n",
        "    \"csv\",\n",
        "    data_files=paths[\"hf_set\"],\n",
        "    column_names=[\"instruction\", \"output\"],\n",
        "    split=\"train\",\n",
        ")\n",
        "raw_hf = raw_hf.add_column(\n",
        "    \"input\",\n",
        "    [\"Construct a research methodology for the given problem.\"] * len(raw_hf)\n",
        ")\n",
        "hf_set = (\n",
        "    raw_hf\n",
        "    .map(formatting_prompts_func, batched=True, remove_columns=raw_hf.column_names)\n",
        "    .select(range(10))\n",
        ")\n",
        "\n",
        "# 4) Sanity checks\n",
        "print(\"train_dataset length:\", len(train_dataset))           # ‚Üí 500\n",
        "print(\"validation_dataset length:\", len(validation_dataset)) # ‚Üí 50\n",
        "print(\"test_dataset length:\", len(test_dataset))             # ‚Üí 50\n",
        "print(\"hf_set length:\", len(hf_set))                         # ‚Üí 10\n",
        "\n",
        "# show that Input now contains your fixed prompt\n",
        "print(\"\\nSample train text:\\n\", train_dataset[0][\"text\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr9KcftEpMjy",
        "outputId": "b7c97e69-5942-479b-bd8a-9dbb9ec64fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample test text:\n",
            " Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "Duration of bladder catheterisation after female genital fistula repair varies widely .We aimed to establish whether 7 day bladder catheterisation was non-inferior to 14 days in terms of incidence of fistula repair breakdown in women with simple fistula .US Agency for International Development .\n",
            "\n",
            "### Response:\n",
            "In this randomised , controlled , open-label , non-inferiority trial , we enrolled patients at eight hospitals in the Democratic Republic of the Congo , Ethiopia , Guinea , Kenya , Niger , Nigeria , Sierra Leone , and Uganda .Consenting patients were eligible if they had a simple fistula that was closed after surgery and remained closed 7 days after surgery , understood study procedures and requirements , and agreed to return for follow-up 3 months after surgery .We excluded women if their fistula was not simple or was radiation-induced , associated with cancer , or due to lymphogranuloma venereum ; if they were pregnant ; or if they had multiple fistula .A research assistant at each site randomly allocated participants 1:1 ( randomly varying block sizes of 4-6 ; stratified by country ) to 7 day or 14 day bladder catheterisation ( via a random allocation sequence computer generated centrally by WHO ) .Outcome assessors were not masked to treatment assignment .The primary outcome was fistula repair breakdown , on the basis of dye test results , any time between 8 days after catheter removal and 3 months after surgery .The non-inferiority margin was 10 % , assessed in the per-protocol population .This trial is registered with ClinicalTrials.gov , number NCT01428830 .<|end_of_text|>\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nSample test text:\\n\", hf_set[4][\"text\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "596da5f195334064b1a0a0211f843946",
            "c23659dbaac84000bbc64590d319b220",
            "18c0cb60d0e241febbdc9393ab08f715",
            "3c0abe829649423482af34b4abd16295",
            "3c047b9f45b749e0891bcc13d8daa97c",
            "5f35602f5f7c49c2a339662a0c89ce99",
            "f1880455351b4344a99b22b271396764",
            "8c4777121e4b45af902b7c9f9bd478b4",
            "a4f693c1cd1246d29295defb468658bd",
            "8e68ec30313d4ab9865f09982cfb8327",
            "1bb717345805483ebc0d766357abe1eb"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "ea61dcc2-b01c-4ce0-85c9-dcd3c82317e9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "596da5f195334064b1a0a0211f843946"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Hugging Face's packing is currently buggy - we're disabling it for now!\n",
            "Unsloth: Hugging Face's packing is currently buggy - we're disabling it for now!\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "import random, math, torch\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "# 1) Build your TrainingArguments ONCE, with remove_unused_columns=False\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    warmup_steps=5,\n",
        "    num_train_epochs=1,\n",
        "    max_steps=-1,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=not is_bfloat16_supported(),\n",
        "    bf16=is_bfloat16_supported(),\n",
        "    logging_steps=1,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=40,\n",
        "    per_device_eval_batch_size=2,\n",
        "    optim=\"adamw_8bit\",\n",
        "    weight_decay=0.01,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    remove_unused_columns=False,\n",
        "    seed=3407,\n",
        "    output_dir=\"outputs\",\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# tokenize\n",
        "def tokenize_fn(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"longest\",\n",
        "    )\n",
        "\n",
        "train_dataset = train_dataset.map(\n",
        "    tokenize_fn,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"],\n",
        ")\n",
        "validation_dataset = validation_dataset.map(\n",
        "    tokenize_fn,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"],\n",
        ")\n",
        "test_dataset = test_dataset.map(\n",
        "    tokenize_fn,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"],\n",
        ")\n",
        "\n",
        "# 2) Instantiate *once*\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    packing=True,\n",
        "    args=training_args,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "h2IiT4dvMVmf",
        "outputId": "339fdb86-8c40-4865-dab0-168789afdf2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
            "Using gradient accumulation will be very slightly less accurate.\n",
            "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 00:30]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200-sample Perplexity on test: 9.981109207850464\n"
          ]
        }
      ],
      "source": [
        "# initial perplexity\n",
        "import math\n",
        "full_metrics = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(\"200-sample Perplexity on test:\", math.exp(full_metrics[\"eval_loss\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWfXALVXRNk1",
        "outputId": "4abd46ff-c7dd-44c3-e71a-f09d4ca2fd03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = NVIDIA A100-SXM4-40GB. Max memory = 39.557 GB.\n",
            "7.625 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZPJFbApgSZD",
        "outputId": "c848c3d2-c9e8-403e-9b1b-75fc049f69e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Human Feedback sample 0:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "High oxidative stress and chronic inflammation can contribute to the pathogenesis of coronary artery disease ( CAD ).Coenzyme Q10 is an endogenous lipid-soluble antioxidant.Statins therapy can reduce the biosynthesis of coenzyme Q10.The purpose of this study was to investigate the effects of a coenzyme Q10 supplement ( 300mg/d ; 150mg/b.i.d ) on antioxidation and anti-inflammation in patients who have CAD during statins therapy.Clinical Trials.gov Identifier : NCT01424761.\n",
            "\n",
            "### Response:\n",
            "The response should be appropriate and should be in the form of a research methodology for the given problem.<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "Patients who were identified by cardiac catheterization as having at least 50 % stenosis of one major coronary artery and who were treated with statins for at least one month were enrolled in this study .The subjects ( n = 51 ) were randomly assigned to the placebo ( n = 24 ) and coenzyme Q10 groups ( Q10-300 group , n = 27 ) .The intervention was administered for 12weeks .The concentrations of coenzyme Q10 , vitamin E , antioxidant enzymes activities ( superoxide dismutase , catalase , and glutathione peroxidase ) , and inflammatory markers [ C-reactive protein ( CRP ) , tumor necrosis factor - ( TNF - ) , and interleukin-6 ( IL-6 ) ] were measured in the 42 subjects ( placebo , n = 19 ; Q10-300 , n = 23 ) who completed the study .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 1:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "Loss of PTEN has been shown to be associated with aggressive behavior of prostate cancer.It is less clear that loss of PTEN also increases the risk of cancer mortality.We investigated the association between PTEN expression and prostate cancer mortality and the potential effect modification by IGF-IR, a direct activator of the phosphoinositide-3-kinase ( PI3K ) pathway.\n",
            "\n",
            "### Response:\n",
            "1. The response should begin by identifying the research problem, which in this case is the relationship between PTEN expression and prostate cancer mortality.\n",
            "2. The response should then describe the methodology used to investigate this relationship, which in this case involves examining the association between PTEN expression and prostate cancer mortality and the potential effect modification by IGF-IR.\n",
            "3. The response should include a description of the statistical analysis that will be performed, such as a logistic regression analysis or a Cox proportional hazards model.\n",
            "4. The response should also include a discussion of potential confounding variables and how they will be accounted for in the analysis.\n",
            "5. The response should conclude by summarizing the proposed research methodology and highlighting its strengths and limitations.<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "Protein expression in tumor was evaluated using tumor tissues obtained from 805 participants of the Physicians ' Health and the Health Professionals Follow-up studies who were diagnosed with prostate cancer and underwent radical prostatectomy .Proportional hazard models were used to assess PTEN expression and its interaction with IGF-IR , in relation to lethal prostate cancer ( cancer-specific death or distant metastases ) .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 2:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "We designed a multicenter randomized trial to compare 3 approaches to the initial respiratory management of preterm neonates : prophylactic surfactant followed by a period of mechanical ventilation ( prophylactic surfactant [ PS ] ) ; prophylactic surfactant with rapid extubation to bubble nasal continuous positive airway pressure ( intubate-surfactant-extubate [ ISX ] ) or initial management with bubble continuous positive airway pressure and selective surfactant treatment ( nCPAP ).\n",
            "\n",
            "### Response:\n",
            "In this research, the study will be conducted in two groups: the experimental group and the control group. The experimental group will be given surfactant, and the control group will not be given surfactant. The study will be conducted over a period of 3 months. During this period, the experimental group will be given surfactant once a week, and the control group will not be given surfactant. After 3 months, the study will be concluded. The results will be analyzed, and the findings will be presented.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "The primary outcome was survival to 28 days of age. Secondary outcomes included respiratory support, duration of ventilation, duration of supplemental oxygen, length of hospital stay, and the incidence of chronic lung disease.\n",
            "\n",
            "### Response:\n",
            "The research methodology will involve the following steps:\n",
            "1. Identify the research question: The research question will be \"What is the effectiveness of surfactant therapy in preterm neonates?\"\n",
            "2. Identify the population: The population will be preterm neonates.\n",
            "3. Identify the intervention: The intervention will be surfactant therapy.\n",
            "4. Identify the comparison group: The comparison group will be preterm neonates who do not receive surfactant therapy.\n",
            "5. Identify the outcome measures: The outcome measures will be survival to 28 days of age, respiratory support, duration of ventilation, duration of supplemental oxygen, length of hospital stay, and the incidence of chronic lung disease.\n",
            "6. Identify the study design: The study design will be a randomized controlled trial.\n",
            "7. Identify the sample size: The sample size will be 100 preterm neonates in each group.\n",
            "8. Identify the data collection methods: The data will be collected using medical records, interviews, and observations.\n",
            "9. Identify the data analysis methods: The data will be analyzed using statistical software, such as SPSS or R.\n",
            "10. Identify the ethical considerations: The ethical considerations will include informed consent, confidentiality, and data security.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "The primary outcome was survival to 28 days of age. Secondary outcomes included respiratory support, duration of ventilation, duration of supplemental oxygen, length of hospital stay, and the incidence of chronic lung disease.\n",
            "\n",
            "### Response:\n",
            "The research methodology will involve the following steps:\n",
            "1. Identify the research question: The research question will be \"What is the effectiveness of surfactant therapy in\n",
            "\n",
            "### Reference:\n",
            "Neonates born at 26 0/7 to 29 6/7 weeks ' gestation were enrolled at participating Vermont Oxford Network centers and randomly assigned to PS , ISX , or nCPAP groups before delivery .Primary outcome was the incidence of death or bronchopulmonary dysplasia ( BPD ) at 36 weeks ' postmenstrual age .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 3:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "Guidelines suggest setting individualised targets for glycaemic control in elderly patients with type 2 diabetes, despite no evidence.We aimed to assess the feasibility of setting and achieving individualised targets over 24 weeks along with conventional HbA1c reduction using vildagliptin versus placebo.Novartis Pharma AG.\n",
            "\n",
            "### Response:\n",
            "The methodology for the research could be as follows:\n",
            "1. The first step would be to identify the research question and define the objectives of the study. This would involve determining the specific question that the research is aiming to answer, such as \"Does setting individualised targets for glycaemic control in elderly patients with type 2 diabetes improve outcomes compared to conventional HbA1c reduction?\" The objectives of the study would be to assess the feasibility of setting and achieving individualised targets over 24 weeks along with conventional HbA1c reduction using vildagliptin versus placebo.\n",
            "2. The next step would be to develop a research design that would be appropriate for the research question and objectives. This could involve conducting a literature review to identify existing studies on the topic, as well as consulting with experts in the field. The research design would need to be ethical and scientifically valid, and would need to take into account the limitations of the study, such as the sample size and the duration of the study.\n",
            "3. The third step would be to identify the research participants and obtain their consent to participate in the study. This would involve identifying a group of elderly patients with type 2 diabetes who would be suitable for the study, and obtaining their consent to participate in the study. The consent form would need to be clear and concise, and would need to outline the risks and benefits of participating in the study.\n",
            "4. The fourth step would be to collect data from the research participants. This could involve conducting interviews, surveys, or other methods of data collection. The data collection process would need to be systematic and standardized, and would need to be conducted in a way that is ethical and respectful of the research participants.\n",
            "5. The fifth step would be to analyze the data and draw conclusions based on the findings. This would involve using statistical methods to analyze the data and determine if there are any significant differences between the groups. The conclusions would need to be based on the data and would need to be supported by the findings.\n",
            "6. The final step would be to disseminate the findings of the study. This could involve publishing the findings in a peer-reviewed journal, presenting the findings at a conference, or sharing the findings with the public through other means. The dissemination of the findings would need to be done in a way that is transparent and accessible to the public.\n",
            "\n",
            "### Explanation:\n",
            "The research methodology for the given problem could be as follows:\n",
            "1. Define the research question and objectives: The research question\n",
            "\n",
            "### Reference:\n",
            "In this multinational , double-blind , 24 week study , we enrolled drug-naive or inadequately controlled ( glycosylated haemoglobin A1c [ HbA1c ] 70 % to 100 % ) patients with type 2 diabetes aged 70 years or older from 45 outpatient centres in Europe .Investigators set individualised treatment targets on the basis of age , baseline HbA1c , comorbidities , and frailty status before a validated automated system randomly assigned patients ( 1:1 ) to vildagliptin ( 50 mg once or twice daily as per label ) or placebo .Coprimary efficacy endpoints were proportion of patients reaching their investigator-defined HbA1c target and HbA1c reduction from baseline to study end .The study is registered with ClinicalTrials.gov , number NCT01257451 , and European Union Drug Regulating Authorities Clinical Trials database , number 2010-022658-18 .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 4:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "Duration of bladder catheterisation after female genital fistula repair varies widely.We aimed to establish whether 7 day bladder catheterisation was non-inferior to 14 days in terms of incidence of fistula repair breakdown in women with simple fistula.US Agency for International Development.\n",
            "\n",
            "### Response:\n",
            "The research methodology is the set of steps and procedures that are used to collect data and analyse it to answer a specific research question. The methodology should be designed to minimise bias and ensure that the data is reliable and valid. The research methodology should be clearly defined and described in the research proposal or paper.\n",
            "\n",
            "### Explanation:\n",
            "The research methodology for the given problem would involve the following steps:\n",
            "\n",
            "1. Define the research question: What is the effect of 7 day bladder catheterisation compared to 14 days in terms of incidence of fistula repair breakdown in women with simple fistula?\n",
            "2. Identify the research design: A randomised controlled trial would be an appropriate design for this study.\n",
            "3. Identify the study population: The study population would be women with simple fistula undergoing fistula repair surgery.\n",
            "4. Identify the intervention: The intervention would be 7 day bladder catheterisation compared to 14 days.\n",
            "5. Identify the outcome measures: The outcome measures would be incidence of fistula repair breakdown.\n",
            "6. Develop the data collection plan: The data collection plan would involve collecting data on the incidence of fistula repair breakdown at 7 and 14 days post-surgery.\n",
            "7. Develop the statistical analysis plan: The statistical analysis plan would involve comparing the incidence of fistula repair breakdown between the two groups using appropriate statistical tests.\n",
            "8. Develop the ethical considerations: The ethical considerations would involve obtaining informed consent from participants, ensuring that the study is conducted in accordance with the principles of the Declaration of Helsinki, and ensuring that the study is conducted in a safe and ethical manner.\n",
            "9. Develop the data management plan: The data management plan would involve storing and managing the data in a secure and confidential manner.\n",
            "10. Develop the dissemination plan: The dissemination plan would involve disseminating the results of the study to relevant stakeholders, including healthcare providers and policymakers.\n",
            "\n",
            "### Instruction:\n",
            "Design a research protocol for the given problem.\n",
            "\n",
            "### Input:\n",
            "Duration of bladder catheterisation after female genital fistula repair varies widely.We aimed to establish whether 7 day bladder catheterisation was non-inferior to 14 days in terms of incidence of fistula repair breakdown in women with simple fistula.US Agency for International Development.\n",
            "\n",
            "### Response:\n",
            "A research protocol is a detailed plan that outlines the methods and procedures that will be used to conduct a research study. The protocol should be designed to minimise bias and ensure that the data is reliable and valid. The research protocol should be clearly defined and described in the\n",
            "\n",
            "### Reference:\n",
            "In this randomised , controlled , open-label , non-inferiority trial , we enrolled patients at eight hospitals in the Democratic Republic of the Congo , Ethiopia , Guinea , Kenya , Niger , Nigeria , Sierra Leone , and Uganda .Consenting patients were eligible if they had a simple fistula that was closed after surgery and remained closed 7 days after surgery , understood study procedures and requirements , and agreed to return for follow-up 3 months after surgery .We excluded women if their fistula was not simple or was radiation-induced , associated with cancer , or due to lymphogranuloma venereum ; if they were pregnant ; or if they had multiple fistula .A research assistant at each site randomly allocated participants 1:1 ( randomly varying block sizes of 4-6 ; stratified by country ) to 7 day or 14 day bladder catheterisation ( via a random allocation sequence computer generated centrally by WHO ) .Outcome assessors were not masked to treatment assignment .The primary outcome was fistula repair breakdown , on the basis of dye test results , any time between 8 days after catheter removal and 3 months after surgery .The non-inferiority margin was 10 % , assessed in the per-protocol population .This trial is registered with ClinicalTrials.gov , number NCT01428830 .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 5:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "This randomized control trial was designed to evaluate the incidence of emergence delirium ( ED ) in preschool children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block.While ED has been described in children receiving sevoflurane or desflurane anesthesia, a direct comparison between the two agents using a validated ED assessment tool has not been reported previously.\n",
            "\n",
            "### Response:\n",
            "This randomized control trial was designed to evaluate the incidence of emergence delirium ( ED ) in preschool children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block. While ED has been described in children receiving sevoflurane or desflurane anesthesia, a direct comparison between the two agents using a validated ED assessment tool has not been reported previously. The incidence of ED in children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block was compared. The incidence of ED in children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block was compared. The incidence of ED in children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block was compared. The incidence of ED in children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block was compared. The incidence of ED in children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block was compared. The incidence of ED in children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block was compared. The incidence of ED in children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block was compared. The incidence of ED in children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block was compared. The incidence of ED in children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block was compared. The incidence of ED in children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block was compared. The incidence of ED in children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block was compared. The incidence of ED in children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block was compared. The incidence of ED in children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block was compared. The incidence of ED in children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block was compared. The incidence of ED in children receiving sevoflurane or\n",
            "\n",
            "### Reference:\n",
            "Two hundred and sixty preschool children scheduled for elective sub-umbilical surgery were randomized to receive sevoflurane or desflurane anesthesia combined with a caudal block .ED was defined as a Paediatric Anesthesia Emergence Delirium scale ( PAED ) 10 points .A delirium-specific score ( ED I ) was calculated from the first three items of the PAED score ( eye contact , purposeful actions , awareness of the surroundings ) and a nonspecific score ( ED II ) from the last two items on the PAED score ( restlessness and inconsolability ) to test the hypothesis that some items of the PAED scale may better reflect clinical ED than others .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 6:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "This report describes whether lossy Joint Photographic Experts Group ( JPEG ) image compression/decompression has an effect on the quantitative assessment of vessel sizes by state-of-the-art quantitative coronary arteriography ( QCA ).The Digital Imaging and Communications in Medicine ( DICOM ) digital exchange standard for angiocardiography prescribes that images must be stored loss free, thereby limiting JPEG compression to a maximum ratio of 2:1.For practical purposes it would be desirable to increase the compression ratio ( CR ), which would lead to lossy image compression.\n",
            "\n",
            "### Response:\n",
            "To construct a research methodology for the given problem, I would suggest the following steps:\n",
            "1. Define the research question: What is the effect of lossy JPEG image compression/decompression on the quantitative assessment of vessel sizes by QCA?\n",
            "2. Formulate the null and alternative hypotheses: H0: Lossy JPEG image compression/decompression does not have an effect on the quantitative assessment of vessel sizes by QCA. H1: Lossy JPEG image compression/decompression has an effect on the quantitative assessment of vessel sizes by QCA.\n",
            "3. Select an appropriate statistical test: Since we are dealing with quantitative data, I would recommend using a t-test or a non-parametric equivalent such as the Mann-Whitney U test.\n",
            "4. Determine the sample size: Based on the desired precision and significance level, I would calculate the required sample size using formulas or online calculators.\n",
            "5. Collect the data: The data can be collected from a sample of angiograms obtained using both lossy and lossless JPEG compression.\n",
            "6. Perform the statistical analysis: Calculate the mean and standard deviation of the vessel sizes obtained using lossy and lossless JPEG compression, and then perform the appropriate statistical test.\n",
            "7. Interpret the results: If the null hypothesis is rejected, it means that there is a statistically significant difference between the vessel sizes obtained using lossy and lossless JPEG compression. If the null hypothesis is not rejected, it means that there is no significant difference between the two compression methods.\n",
            "8. Draw conclusions: Based on the statistical analysis and interpretation of the results, I would conclude whether lossy JPEG image compression/decompression has an effect on the quantitative assessment of vessel sizes by QCA.<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "A series of 48 obstructed coronary segments were compressed/decompressed at CR 1:1 ( uncompressed ) , 6:1 , 10:1 and 16:1 and analyzed blindly and in random order using the QCA-CMS analytical software .Similar catheter and vessel start - and end-points were used within each image quartet , respectively .All measurements were repeated after several weeks using newly selected start - and end-points .Three different sub-analyses were carried out : the intra-observer , fixed inter-compression and variable inter-compression analyses , with increasing potential error sources , respectively .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 7:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "This open-label study assessed the safety and immunogenicity of two doses and two routes of the anti-idiotypic monoclonal antibody abagovomab ( formerly ACA125 ) in patients with epithelial ovarian, fallopian tube, or primary peritoneal cancer.\n",
            "\n",
            "### Response:\n",
            "The research methodology will consist of a number of steps. First, the researchers will define the objectives of the study and the hypotheses they wish to test. Next, they will develop a study design that will allow them to collect the data they need to test their hypotheses. This may involve selecting a sample of patients, determining the variables they wish to measure, and choosing the methods they will use to collect the data. Once the data have been collected, the researchers will analyze the data using appropriate statistical methods. Finally, they will interpret the results and draw conclusions about the safety and immunogenicity of abagovomab in patients with epithelial ovarian, fallopian tube, or primary peritoneal cancer.<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "Eligible patients from the three participating institutions were any stage at diagnosis , had relapsed , and had complete or partial response to additional chemotherapy .Patients were randomized to receive abagovomab at 2.0 versus 0.2 mg and i.m. versus s.c. for four immunizations every 2 weeks and then monthly for two additional immunizations .Planned evaluation included interval physical examinations and laboratory assessments with immune assessment , including HLA typing , human anti-mouse antibody , ELISA , and enzyme-linked immunospot .Patients were required to remain on study until week 10 ( the first post-baseline Ab3 determination ) to be considered for immunologic assessment .The primary end points were safety and immunogenicity primarily determined by Ab3 response .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 8:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "To investigate the adjunctive use of mifepristone in second-trimester induction abortions using misoprostol 1 day after feticidal digoxin.Clinicaltrials.gov, www.clinicaltrials.gov, NCT00382538\n",
            "\n",
            "### Response:\n",
            "<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "This is a randomized , placebo-controlled , double-blind trial of mifepristone in second-trimester induction termination using misoprostol after feticidal digoxin .Women seeking abortion between 18 and 23 weeks of gestation were offered enrollment .At the time of digoxin amnioinfusion , participants received a randomly allocated , identical-appearing capsule containing either mifepristone , 200 mg , or placebo .Patients returned the following day for induction with buccal misoprostol .The primary outcome was the time interval from the first misoprostol dose to abortion .Analysis utilized survival curves with log-rank testing .I.<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 9:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "To assess the influence of the serotonin transporter variable number of tandem repeat ( HTT-VNTR ) polymorphism and the serotonin transporter-gene-linked polymorphic region ( HTTLPR ) polymorphism on development of side effects under antidepressant therapy.\n",
            "\n",
            "### Response:\n",
            "The research methodology should include the following steps:\n",
            "1. Identify the specific research question that the research methodology is intended to answer.\n",
            "2. Define the study design, which may include a prospective cohort study, a case-control study, or a randomized controlled trial.\n",
            "3. Identify the study population, which may include patients with depression or other psychiatric disorders, as well as healthy individuals.\n",
            "4. Specify the study variables, which may include the HTT-VNTR polymorphism, the HTTLPR polymorphism, and the side effects of antidepressant therapy.\n",
            "5. Develop the data collection methods, which may include questionnaires, interviews, or laboratory tests.\n",
            "6. Describe the statistical analysis methods, which may include chi-square tests, t-tests, or regression analysis.\n",
            "7. Discuss the ethical considerations and potential limitations of the research methodology.\n",
            "\n",
            "### Instruction:\n",
            "Develop a hypothesis for the given problem.\n",
            "\n",
            "### Input:\n",
            "To assess the influence of the serotonin transporter variable number of tandem repeat ( HTT-VNTR ) polymorphism and the serotonin transporter-gene-linked polymorphic region ( HTTLPR ) polymorphism on development of side effects under antidepressant therapy.\n",
            "\n",
            "### Response:\n",
            "The hypothesis for the given problem can be formulated as follows:\n",
            "The HTT-VNTR polymorphism and the HTTLPR polymorphism have an influence on the development of side effects under antidepressant therapy.\n",
            "This hypothesis can be tested by conducting a case-control study or a prospective cohort study, where the study population consists of patients with depression or other psychiatric disorders, as well as healthy individuals. The study variables include the HTT-VNTR polymorphism, the HTTLPR polymorphism, and the side effects of antidepressant therapy. Data collection methods may include questionnaires, interviews, or laboratory tests. Statistical analysis methods may include chi-square tests, t-tests, or regression analysis. Ethical considerations and potential limitations of the research methodology should also be discussed.\n",
            "\n",
            "### Instruction:\n",
            "Develop a research design for the given problem.\n",
            "\n",
            "### Input:\n",
            "To assess the influence of the serotonin transporter variable number of tandem repeat ( HTT-VNTR ) polymorphism and the serotonin transporter-gene-linked polymorphic region ( HTTLPR ) polymorphism on development of side effects under antidepressant therapy.\n",
            "\n",
            "### Response:\n",
            "The research design for the given problem can be formulated as follows:\n",
            "The research design should include the following steps:\n",
            "1. Identify the specific research question that the research methodology is intended to answer.\n",
            "2. Define the study design, which may include a\n",
            "\n",
            "### Reference:\n",
            "A total of 109 depressive in-patients treated with various antidepressants according to local clinical practice were included in the investigation .Four weeks after admission to hospital , side effects were assessed by using a modified version of the dosage record and treatment emergent symptoms scale ( DOTES ) .Differences in side effects between the genotype groups of both polymorphisms were analyzed using the Fisher 's exact test .<|end_of_text|>\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Prepare a list to collect all generated responses\n",
        "\n",
        "FastLanguageModel.for_inference(model)  # enable optimized inference\n",
        "\n",
        "for i, sample in enumerate(hf_set):\n",
        "    # 1) Print the original formatted human‚Äêfeedback sample\n",
        "    sample_text = sample[\"text\"]\n",
        "\n",
        "    # Split on the three markers; the regex will drop them for us\n",
        "    parts = re.split(\n",
        "        r\"\\r?\\n\\r?\\n### Instruction:\\r?\\n|\\r?\\n\\r?\\n### Input:\\r?\\n|\\r?\\n\\r?\\n### Response:\\r?\\n\",\n",
        "        sample_text\n",
        "    )\n",
        "\n",
        "    # re.split returns ['', '<instr>', '<inp>', '<resp>'], so skip the first empty\n",
        "    _, instruction, input, reference = parts\n",
        "\n",
        "    # strip any stray whitespace\n",
        "    instruction = instruction.strip()\n",
        "    input = input.strip()\n",
        "    reference = reference.strip()\n",
        "\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "    inputs = tokenizer(\n",
        "    [\n",
        "        alpaca_prompt.format(\n",
        "            instruction, # Instruction\n",
        "            input, # Input\n",
        "            \"\", # output - leave this blank for generation!\n",
        "        )\n",
        "    ], return_tensors = \"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens = 500, use_cache = True)\n",
        "    prompt = tokenizer.batch_decode(outputs)[0]\n",
        "\n",
        "    full = (\n",
        "        prompt  + \"\\n\\n\"\n",
        "        \"### Reference:\\n\"   + reference\n",
        "    )\n",
        "    print(f\"\\nHuman Feedback sample {i}:\\n{full}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "IHDroW5eRSIK",
        "outputId": "c83c70d6-8eb8-4d9e-eb1c-aba08021142b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 3,200 | Num Epochs = 1 | Total steps = 400\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [400/400 19:16, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Model Preparation Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.386100</td>\n",
              "      <td>1.384224</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.453900</td>\n",
              "      <td>1.374160</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.493100</td>\n",
              "      <td>1.369413</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.367200</td>\n",
              "      <td>1.367253</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.370800</td>\n",
              "      <td>1.364300</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.224600</td>\n",
              "      <td>1.364179</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.321300</td>\n",
              "      <td>1.362745</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.312300</td>\n",
              "      <td>1.361318</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.377200</td>\n",
              "      <td>1.360534</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.181700</td>\n",
              "      <td>1.360130</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='400' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 05:43]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=400, training_loss=1.3789241325855255, metrics={'train_runtime': 1166.0012, 'train_samples_per_second': 2.744, 'train_steps_per_second': 0.343, 'total_flos': 9.597668637794304e+16, 'train_loss': 1.3789241325855255})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "L-ClVYwCRUhW",
        "outputId": "03d2300f-3d12-42bc-e51f-bddffbfa78ce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 00:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200-sample Perplexity: 3.878508798187442\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "full_metrics = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(\"200-sample Perplexity:\", math.exp(full_metrics[\"eval_loss\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22bDOOjyyRob",
        "outputId": "7005667e-28b3-4034-f33a-213db5730f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Human Feedback sample 0:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "High oxidative stress and chronic inflammation can contribute to the pathogenesis of coronary artery disease ( CAD ).Coenzyme Q10 is an endogenous lipid-soluble antioxidant.Statins therapy can reduce the biosynthesis of coenzyme Q10.The purpose of this study was to investigate the effects of a coenzyme Q10 supplement ( 300mg/d ; 150mg/b.i.d ) on antioxidation and anti-inflammation in patients who have CAD during statins therapy.Clinical Trials.gov Identifier : NCT01424761.\n",
            "\n",
            "### Response:\n",
            "This study was a randomized, double-blind, placebo-controlled, parallel-group trial.A total of 120 patients with CAD were randomly assigned to 2 groups : coenzyme Q10 ( n = 60 ) and placebo ( n = 60 ).The patients in the coenzyme Q10 group received coenzyme Q10 supplement ( 300mg/d ; 150mg/b.i.d ) for 3 months, and the patients in the placebo group received placebo for 3 months.<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "Patients who were identified by cardiac catheterization as having at least 50 % stenosis of one major coronary artery and who were treated with statins for at least one month were enrolled in this study .The subjects ( n = 51 ) were randomly assigned to the placebo ( n = 24 ) and coenzyme Q10 groups ( Q10-300 group , n = 27 ) .The intervention was administered for 12weeks .The concentrations of coenzyme Q10 , vitamin E , antioxidant enzymes activities ( superoxide dismutase , catalase , and glutathione peroxidase ) , and inflammatory markers [ C-reactive protein ( CRP ) , tumor necrosis factor - ( TNF - ) , and interleukin-6 ( IL-6 ) ] were measured in the 42 subjects ( placebo , n = 19 ; Q10-300 , n = 23 ) who completed the study .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 1:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "Loss of PTEN has been shown to be associated with aggressive behavior of prostate cancer.It is less clear that loss of PTEN also increases the risk of cancer mortality.We investigated the association between PTEN expression and prostate cancer mortality and the potential effect modification by IGF-IR, a direct activator of the phosphoinositide-3-kinase ( PI3K ) pathway.\n",
            "\n",
            "### Response:\n",
            "The study included 266 men with prostate cancer who were diagnosed with prostate cancer in the placebo arm of the Prostate Cancer Prevention Trial.Immunohistochemical staining was performed on tumor tissue to determine the expression of PTEN and IGF-IR.The association between PTEN expression and prostate cancer mortality was assessed using Cox regression models.<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "Protein expression in tumor was evaluated using tumor tissues obtained from 805 participants of the Physicians ' Health and the Health Professionals Follow-up studies who were diagnosed with prostate cancer and underwent radical prostatectomy .Proportional hazard models were used to assess PTEN expression and its interaction with IGF-IR , in relation to lethal prostate cancer ( cancer-specific death or distant metastases ) .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 2:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "We designed a multicenter randomized trial to compare 3 approaches to the initial respiratory management of preterm neonates : prophylactic surfactant followed by a period of mechanical ventilation ( prophylactic surfactant [ PS ] ) ; prophylactic surfactant with rapid extubation to bubble nasal continuous positive airway pressure ( intubate-surfactant-extubate [ ISX ] ) or initial management with bubble continuous positive airway pressure and selective surfactant treatment ( nCPAP ).\n",
            "\n",
            "### Response:\n",
            "Between 1997 and 2000, 3,045 infants born between 23 and 31 weeks'gestation and weighing 500 to 1,500 g were enrolled in 9 European neonatal intensive care units.Infants were randomly assigned to 1 of the 3 initial respiratory management strategies.The primary end point was the incidence of chronic lung disease ( CLD ), defined as the need for supplemental oxygen at 36 weeks'postmenstrual age.<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "Neonates born at 26 0/7 to 29 6/7 weeks ' gestation were enrolled at participating Vermont Oxford Network centers and randomly assigned to PS , ISX , or nCPAP groups before delivery .Primary outcome was the incidence of death or bronchopulmonary dysplasia ( BPD ) at 36 weeks ' postmenstrual age .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 3:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "Guidelines suggest setting individualised targets for glycaemic control in elderly patients with type 2 diabetes, despite no evidence.We aimed to assess the feasibility of setting and achieving individualised targets over 24 weeks along with conventional HbA1c reduction using vildagliptin versus placebo.Novartis Pharma AG.\n",
            "\n",
            "### Response:\n",
            "Patients aged 70 years or older with type 2 diabetes and HbA1c 7.5-9.5 % were randomised to vildagliptin 50 mg twice daily or placebo.Individualised targets were set in the first 4 weeks of the trial and achieved in the subsequent 20 weeks.<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "In this multinational , double-blind , 24 week study , we enrolled drug-naive or inadequately controlled ( glycosylated haemoglobin A1c [ HbA1c ] 70 % to 100 % ) patients with type 2 diabetes aged 70 years or older from 45 outpatient centres in Europe .Investigators set individualised treatment targets on the basis of age , baseline HbA1c , comorbidities , and frailty status before a validated automated system randomly assigned patients ( 1:1 ) to vildagliptin ( 50 mg once or twice daily as per label ) or placebo .Coprimary efficacy endpoints were proportion of patients reaching their investigator-defined HbA1c target and HbA1c reduction from baseline to study end .The study is registered with ClinicalTrials.gov , number NCT01257451 , and European Union Drug Regulating Authorities Clinical Trials database , number 2010-022658-18 .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 4:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "Duration of bladder catheterisation after female genital fistula repair varies widely.We aimed to establish whether 7 day bladder catheterisation was non-inferior to 14 days in terms of incidence of fistula repair breakdown in women with simple fistula.US Agency for International Development.\n",
            "\n",
            "### Response:\n",
            "We conducted a pragmatic, multicentre, open-label, non-inferiority randomised controlled trial in four hospitals in Ethiopia and Nigeria.We randomly assigned women aged 18 years or older with simple fistula to 7 day ( n = 50 ) or 14 day ( n = 50 ) catheterisation after fistula repair.We used a computer-generated randomisation list, with block sizes of four, to allocate participants to each treatment group.We used a secure, web-based randomisation system to generate the randomisation list and to allocate participants to treatment groups.The primary outcome was fistula breakdown at 6 weeks after repair.This outcome was assessed by the surgeon who repaired the fistula.We did a subgroup analysis of fistula breakdown in women with a history of genital fistula repair.This trial is registered with ClinicalTrials.gov, number NCT01226747.<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "In this randomised , controlled , open-label , non-inferiority trial , we enrolled patients at eight hospitals in the Democratic Republic of the Congo , Ethiopia , Guinea , Kenya , Niger , Nigeria , Sierra Leone , and Uganda .Consenting patients were eligible if they had a simple fistula that was closed after surgery and remained closed 7 days after surgery , understood study procedures and requirements , and agreed to return for follow-up 3 months after surgery .We excluded women if their fistula was not simple or was radiation-induced , associated with cancer , or due to lymphogranuloma venereum ; if they were pregnant ; or if they had multiple fistula .A research assistant at each site randomly allocated participants 1:1 ( randomly varying block sizes of 4-6 ; stratified by country ) to 7 day or 14 day bladder catheterisation ( via a random allocation sequence computer generated centrally by WHO ) .Outcome assessors were not masked to treatment assignment .The primary outcome was fistula repair breakdown , on the basis of dye test results , any time between 8 days after catheter removal and 3 months after surgery .The non-inferiority margin was 10 % , assessed in the per-protocol population .This trial is registered with ClinicalTrials.gov , number NCT01428830 .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 5:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "This randomized control trial was designed to evaluate the incidence of emergence delirium ( ED ) in preschool children receiving sevoflurane or desflurane anesthesia combined with an effective caudal block.While ED has been described in children receiving sevoflurane or desflurane anesthesia, a direct comparison between the two agents using a validated ED assessment tool has not been reported previously.\n",
            "\n",
            "### Response:\n",
            "A total of 64 children, aged 3-5 years, scheduled for tonsillectomy with or without adenoidectomy, were randomly allocated to receive either sevoflurane ( group S ) or desflurane ( group D ) anesthesia.The primary outcome was the incidence of ED.The secondary outcomes included the incidence of adverse events and the duration of surgery.<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "Two hundred and sixty preschool children scheduled for elective sub-umbilical surgery were randomized to receive sevoflurane or desflurane anesthesia combined with a caudal block .ED was defined as a Paediatric Anesthesia Emergence Delirium scale ( PAED ) 10 points .A delirium-specific score ( ED I ) was calculated from the first three items of the PAED score ( eye contact , purposeful actions , awareness of the surroundings ) and a nonspecific score ( ED II ) from the last two items on the PAED score ( restlessness and inconsolability ) to test the hypothesis that some items of the PAED scale may better reflect clinical ED than others .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 6:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "This report describes whether lossy Joint Photographic Experts Group ( JPEG ) image compression/decompression has an effect on the quantitative assessment of vessel sizes by state-of-the-art quantitative coronary arteriography ( QCA ).The Digital Imaging and Communications in Medicine ( DICOM ) digital exchange standard for angiocardiography prescribes that images must be stored loss free, thereby limiting JPEG compression to a maximum ratio of 2:1.For practical purposes it would be desirable to increase the compression ratio ( CR ), which would lead to lossy image compression.\n",
            "\n",
            "### Response:\n",
            "Images of 20 patients were compressed with a CR of 1:1, 1.5:1, 2:1, 4:1, and 8:1.The images were decompressed by the same algorithm.Quantitative assessment of vessel sizes was performed by QCA.<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "A series of 48 obstructed coronary segments were compressed/decompressed at CR 1:1 ( uncompressed ) , 6:1 , 10:1 and 16:1 and analyzed blindly and in random order using the QCA-CMS analytical software .Similar catheter and vessel start - and end-points were used within each image quartet , respectively .All measurements were repeated after several weeks using newly selected start - and end-points .Three different sub-analyses were carried out : the intra-observer , fixed inter-compression and variable inter-compression analyses , with increasing potential error sources , respectively .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 7:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "This open-label study assessed the safety and immunogenicity of two doses and two routes of the anti-idiotypic monoclonal antibody abagovomab ( formerly ACA125 ) in patients with epithelial ovarian, fallopian tube, or primary peritoneal cancer.\n",
            "\n",
            "### Response:\n",
            "Patients with advanced disease received two doses of abagovomab at 0 and 3 months by intramuscular or subcutaneous injection.Blood samples were obtained for the assessment of safety, and for the determination of anti-CA125 IgG, IgA, and IgM antibodies.<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "Eligible patients from the three participating institutions were any stage at diagnosis , had relapsed , and had complete or partial response to additional chemotherapy .Patients were randomized to receive abagovomab at 2.0 versus 0.2 mg and i.m. versus s.c. for four immunizations every 2 weeks and then monthly for two additional immunizations .Planned evaluation included interval physical examinations and laboratory assessments with immune assessment , including HLA typing , human anti-mouse antibody , ELISA , and enzyme-linked immunospot .Patients were required to remain on study until week 10 ( the first post-baseline Ab3 determination ) to be considered for immunologic assessment .The primary end points were safety and immunogenicity primarily determined by Ab3 response .<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 8:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "To investigate the adjunctive use of mifepristone in second-trimester induction abortions using misoprostol 1 day after feticidal digoxin.Clinicaltrials.gov, www.clinicaltrials.gov, NCT00382538\n",
            "\n",
            "### Response:\n",
            "A randomized controlled trial of 72 women undergoing second-trimester medical abortion at 12-24 weeks of gestation.Women were randomized to receive either mifepristone 200 mg or placebo, 1 day after administration of 1 mg of digoxin.All women received 800 microg of oral misoprostol.The primary outcome was the proportion of women with complete abortion by 10 days after the initial administration of misoprostol.Secondary outcomes included the proportion of women with complete abortion by 14 days, time to complete abortion, and adverse events.<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "This is a randomized , placebo-controlled , double-blind trial of mifepristone in second-trimester induction termination using misoprostol after feticidal digoxin .Women seeking abortion between 18 and 23 weeks of gestation were offered enrollment .At the time of digoxin amnioinfusion , participants received a randomly allocated , identical-appearing capsule containing either mifepristone , 200 mg , or placebo .Patients returned the following day for induction with buccal misoprostol .The primary outcome was the time interval from the first misoprostol dose to abortion .Analysis utilized survival curves with log-rank testing .I.<|end_of_text|>\n",
            "\n",
            "Human Feedback sample 9:\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Construct a research methodology for the given problem.\n",
            "\n",
            "### Input:\n",
            "To assess the influence of the serotonin transporter variable number of tandem repeat ( HTT-VNTR ) polymorphism and the serotonin transporter-gene-linked polymorphic region ( HTTLPR ) polymorphism on development of side effects under antidepressant therapy.\n",
            "\n",
            "### Response:\n",
            "In a prospective, randomized, multicenter, open-label trial, patients were treated with venlafaxine ( n = 57 ), paroxetine ( n = 58 ), or fluoxetine ( n = 59 ) for 12 weeks.The HTTLPR polymorphism was analyzed in 177 patients, the HTT-VNTR polymorphism in 179 patients.<|end_of_text|>\n",
            "\n",
            "### Reference:\n",
            "A total of 109 depressive in-patients treated with various antidepressants according to local clinical practice were included in the investigation .Four weeks after admission to hospital , side effects were assessed by using a modified version of the dosage record and treatment emergent symptoms scale ( DOTES ) .Differences in side effects between the genotype groups of both polymorphisms were analyzed using the Fisher 's exact test .<|end_of_text|>\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Prepare a list to collect all generated responses\n",
        "\n",
        "FastLanguageModel.for_inference(model)  # enable optimized inference\n",
        "\n",
        "for i, sample in enumerate(hf_set):\n",
        "    # 1) Print the original formatted human‚Äêfeedback sample\n",
        "    sample_text = sample[\"text\"]\n",
        "    # assume sample_text is your full Alpaca‚Äêstyle string\n",
        "    # e.g. \"‚Ä¶\\n\\n### Instruction:\\n<instr>\\n\\n### Input:\\n<inp>\\n\\n### Response:\\n<resp><|end_of_text|>\"\n",
        "\n",
        "    # Split on the three markers; the regex will drop them for us\n",
        "    parts = re.split(\n",
        "        r\"\\r?\\n\\r?\\n### Instruction:\\r?\\n|\\r?\\n\\r?\\n### Input:\\r?\\n|\\r?\\n\\r?\\n### Response:\\r?\\n\",\n",
        "        sample_text\n",
        "    )\n",
        "\n",
        "    # re.split returns ['', '<instr>', '<inp>', '<resp>'], so skip the first empty\n",
        "    _, instruction, input, reference = parts\n",
        "\n",
        "    # strip any stray whitespace\n",
        "    instruction = instruction.strip()\n",
        "    input = input.strip()\n",
        "    reference = reference.strip()\n",
        "\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "    inputs = tokenizer(\n",
        "    [\n",
        "        alpaca_prompt.format(\n",
        "            instruction, # Instruction\n",
        "            input, # Input\n",
        "            \"\", # output - leave this blank for generation!\n",
        "        )\n",
        "    ], return_tensors = \"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens = 500, use_cache = True)\n",
        "    prompt = tokenizer.batch_decode(outputs)[0]\n",
        "\n",
        "    # 2) Build the generation prompt by keeping everything up to \"### Response:\"\n",
        "    #prompt = \"### Response:\\n\" + sample_text.split(\"### Response:\")[1]\n",
        "\n",
        "    # 5) Save and print the generated reply\n",
        "    # now concatenate strings\n",
        "    full = (\n",
        "        prompt  + \"\\n\\n\"\n",
        "        \"### Reference:\\n\"   + reference\n",
        "    )\n",
        "    print(f\"\\nHuman Feedback sample {i}:\\n{full}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "0ead0337-4d51-4007-be34-1714a36ed6fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = NVIDIA A100-SXM4-40GB. Max memory = 39.557 GB.\n",
            "7.625 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "596da5f195334064b1a0a0211f843946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c23659dbaac84000bbc64590d319b220",
              "IPY_MODEL_18c0cb60d0e241febbdc9393ab08f715",
              "IPY_MODEL_3c0abe829649423482af34b4abd16295"
            ],
            "layout": "IPY_MODEL_3c047b9f45b749e0891bcc13d8daa97c"
          }
        },
        "c23659dbaac84000bbc64590d319b220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f35602f5f7c49c2a339662a0c89ce99",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f1880455351b4344a99b22b271396764",
            "value": "Map:‚Äá100%"
          }
        },
        "18c0cb60d0e241febbdc9393ab08f715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c4777121e4b45af902b7c9f9bd478b4",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4f693c1cd1246d29295defb468658bd",
            "value": 400
          }
        },
        "3c0abe829649423482af34b4abd16295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e68ec30313d4ab9865f09982cfb8327",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1bb717345805483ebc0d766357abe1eb",
            "value": "‚Äá400/400‚Äá[00:00&lt;00:00,‚Äá2293.06‚Äáexamples/s]"
          }
        },
        "3c047b9f45b749e0891bcc13d8daa97c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f35602f5f7c49c2a339662a0c89ce99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1880455351b4344a99b22b271396764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c4777121e4b45af902b7c9f9bd478b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f693c1cd1246d29295defb468658bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e68ec30313d4ab9865f09982cfb8327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bb717345805483ebc0d766357abe1eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}